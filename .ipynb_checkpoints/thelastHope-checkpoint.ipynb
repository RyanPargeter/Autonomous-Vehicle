{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import time\n",
    "import imutils\n",
    "from scipy.spatial import distance\n",
    "from typing import NamedTuple\n",
    "import collections\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits import mplot3d\n",
    "import math\n",
    "#%matplotlib inline\n",
    "from IPython import display\n",
    "import objectDetection\n",
    "import objectTracking\n",
    "from ekfSlam import Slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pnts =  [508.       -30.5        9.089869]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'COLORS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-35211520ecab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{},{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             cv2.rectangle(frame, (old_objects[obj][3], old_objects[obj][4]), (old_objects[obj][5], old_objects[obj][6]),\n\u001b[1;32m--> 141\u001b[1;33m                 COLORS[obj], 2)\n\u001b[0m\u001b[0;32m    142\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mold_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m15\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m15\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mold_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             cv2.putText(frame, label, (old_objects[obj][3], y),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'COLORS' is not defined"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/rparg/Downloads/data_odometry_poses/dataset/poses/00.txt') as f:\n",
    "\t\t\ttruth =f.readlines()\n",
    "\n",
    "slam = Slam()\n",
    "net = cv2.dnn.readNetFromCaffe('SingleShotDetector/MobileNetSSD_deploy.prototxt.txt', 'SingleShotDetector/MobileNetSSD_deploy.caffemodel')\n",
    "\n",
    "\n",
    "objectId = 0\n",
    "old_objects = collections.OrderedDict()\n",
    "\n",
    "# SLAM variables\n",
    "#initialization\n",
    "\n",
    "#noise\n",
    "q = np.array([0.0001, 0.0001])\n",
    "Q = np.diag(q**2)\n",
    "\n",
    "m = np.array([2*math.pi/180, .25])\n",
    "M = np.diag(m ** 2)\n",
    "\n",
    "R = np.array([[0],[0],[0]])\n",
    "u = np.array([[1], [0.0]])\n",
    "\n",
    "#initialize a landmark array\n",
    "\n",
    "y = np.zeros([2, 52])\n",
    "\n",
    "# estimator\n",
    "\n",
    "robotSize = 3\n",
    "x = np.zeros([robotSize + np.size(y), 1])\n",
    "P = np.zeros([np.size(x), np.size(x)])\n",
    "\n",
    "mapspace = np.arange(1,np.size(x))\n",
    "l = np.zeros([2, np.size(y)])\n",
    "\n",
    "r = np.nonzero(mapspace)[0][0:3]\n",
    "mapspace[r] = 0\n",
    "x[r] = R\n",
    "\n",
    "P[r[:, np.newaxis],r] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=112, blockSize=15)\n",
    "\n",
    "\n",
    "\n",
    "image = 0\n",
    "cunt = 0\n",
    "traj = np.zeros((600,600,3), dtype=np.uint8)\n",
    "for img_id in range(4541):\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "#     (grabbed, frame) = vsLeft.read()\n",
    "#     (grabbed, frame1) = vsRight.read()\n",
    "    \n",
    "#     if not grabbed:\n",
    "#         break\n",
    "    \n",
    "#     frame = vs.read()\n",
    "\n",
    "    lftFrame = cv2.imread('/Users/rparg/Downloads/00/image_0/'+str(img_id).zfill(6)+'.png', 0)\n",
    "    rtFrame = cv2.imread('/Users/rparg/Downloads/00/image_1/'+str(img_id).zfill(6)+'.png', 0)\n",
    "    image += 1\n",
    "    \n",
    "    lftFrame = cv2.cvtColor(lftFrame,cv2.COLOR_GRAY2RGB)\n",
    "    rtFrame = cv2.cvtColor(rtFrame,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    frame = imutils.resize(lftFrame, width=400)\n",
    "    frame1 = imutils.resize(rtFrame, width=400)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    right = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) \n",
    "    left = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    disparity = stereo.compute(left, right)\n",
    "    disparity = cv2.normalize(disparity, None, alpha = 0, beta = 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "\n",
    "    h, w = disparity.shape\n",
    "    f = 0.1*w                          # guess for focal length\n",
    "    silly = np.float32([[1, 0,  0, w / 2],\n",
    "                    [0, -1,  0,  h / 2],  # turn points 180 deg around x-axis,\n",
    "                    [0, 0, f,  0],  # so that y-axis looks up\n",
    "                    [0, 0,  0,  1]])\n",
    "    \n",
    "    real_points = cv2.reprojectImageTo3D(disparity, silly)\n",
    "\n",
    "    \n",
    "    \n",
    "    new_objects = objectDetection.doObjectDetection(net, frame, real_points, x)\n",
    "   \n",
    "    objectId, old_objects,new_objects = objectTracking.trackObjects(objectId,old_objects,new_objects, x)    \n",
    "      \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     ax = plt.axes()\n",
    "#     ax.set_xlabel('x')\n",
    "#     ax.set_ylabel('y')\n",
    "#    # ax.set_zlabel('z')\n",
    "    \n",
    "#     ax.scatter( 0,0,marker='s')\n",
    "\n",
    "    \n",
    "    for obj in old_objects:\n",
    "#         xarr = []\n",
    "#         yarr = []\n",
    "#         zarr = []\n",
    "#         if old_objects[obj][0] == 'bottle':\n",
    "            \n",
    "#             for y in range(old_objects[obj][3], old_objects[obj][5]):\n",
    "#                 for x in range(old_objects[obj][4], old_objects[obj][6]):\n",
    "#                     realxyz = real_points[x,y]\n",
    "#                     xarr.append(realxyz[0])\n",
    "#                     yarr.append(realxyz[1])\n",
    "#                     zarr.append(realxyz[2])\n",
    "\n",
    "\n",
    "            #work out average and use for plotting\n",
    "\n",
    "#             ax.scatter(sum(zarr) / len(zarr), old_objects[obj][1])\n",
    "#             print(sum(zarr) / len(zarr))\n",
    "#             print(old_objects[obj][1])\n",
    "\n",
    "\n",
    "        if old_objects[obj][7] == 0:\n",
    "            # display the prediction\n",
    "            label = \"{},{}\".format(old_objects[obj][0], obj)\n",
    "            cv2.rectangle(frame, (old_objects[obj][3], old_objects[obj][4]), (old_objects[obj][5], old_objects[obj][6]),\n",
    "                objectDetection.COLORS[obj], 2)\n",
    "            y = old_objects[obj][4] - 15 if old_objects[obj][4] - 15 > 15 else old_objects[obj][4] + 15\n",
    "            cv2.putText(frame, label, (old_objects[obj][3], y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[obj], 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # robot movement\n",
    "    ## Prediction\n",
    "    x[r], R_r, R_n = slam.robotMove(x[r], u) # might need to add noise here at some point dunno\n",
    "    \n",
    "    P_rr = P[r[:, np.newaxis],r] # no idea if there is a better way\n",
    "    P[r,:] = R_r@P[r,:]\n",
    "    P[:,r] = P[r,:].conj().T\n",
    "    P[r[:, np.newaxis],r] = R_r @ P_rr @ R_r.conj().T + R_n @ Q @ R_n.conj().T\n",
    "    \n",
    "    \n",
    "    # deal with known landmarks\n",
    "    if len(np.nonzero(l[0,:])[0]) >= 1:\n",
    "        for lid in old_objects:\n",
    "            if old_objects[lid][7] == 0:\n",
    "                \n",
    "                # The expected measrment\n",
    "                blip = int(l[:, lid][0])\n",
    "                blap = int(l[:, lid][1])\n",
    "                if blip > 0:\n",
    "                    e, E_r, E_l = slam.project(x[r], np.vstack((x[blip], x[blap])))\n",
    "\n",
    "\n",
    "\n",
    "                    E_rl = np.hstack((E_r, E_l))\n",
    "                    rl = np.hstack((r, l[:,lid].conj().T))\n",
    "                    rl = rl.astype(int)\n",
    "                    E = E_rl @ P[rl[:, np.newaxis],rl] @ E_rl.conj().T\n",
    "\n",
    "\n",
    "\n",
    "                    # The actual measurment\n",
    "    #                 pnts = real_points[old_objects[lid][1], old_objects[lid][2]]\n",
    "                    yi = np.array([[old_objects[lid][1]], [old_objects[lid][2]]])\n",
    "                    # need to project first\n",
    "                    yi,tmp1,tmp2 = slam.project(x[r], yi)\n",
    "\n",
    "                    # Innovation\n",
    "\n",
    "                    z = yi - e\n",
    "\n",
    "                    if z[1] > math.pi:\n",
    "                        z[1] = z[1] - 2*math.pi\n",
    "                    if z[1] < -math.pi:\n",
    "                        z[1] = z[1] + 2*math.pi\n",
    "\n",
    "                    Z = M + E\n",
    "\n",
    "\n",
    "\n",
    "                    # Kalman Gain\n",
    "\n",
    "                    K = P[:, rl] @ E_rl.conj().T @ pow(Z,-1) #np.nan_to_num might be needed\n",
    "\n",
    "                    # Update\n",
    "\n",
    "                    x = x + K @ z\n",
    "                    P = P - K @ Z @ K.conj().T\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    \n",
    "    # initialize new landmarks\n",
    "    if len(new_objects) > 0:\n",
    "        tmp = np.nonzero(l[1,:] == 0)[0] \n",
    "\n",
    "        if len(tmp) > 0:\n",
    "            lid = tmp[0]\n",
    "            emptyMapSpaces = np.nonzero(mapspace)\n",
    "            if len(emptyMapSpaces[0]) > 1:\n",
    "                s = np.array([emptyMapSpaces[0][0], emptyMapSpaces[0][1]])\n",
    "                if len(s) > 1:\n",
    "                    mapspace[s] = 0\n",
    "                    l[:,lid] = s.conj().T\n",
    "\n",
    "\n",
    "                # Measurment\n",
    "                \n",
    "                    yi = np.array([[new_objects[0][1]], [new_objects[0][2]]])\n",
    "#                     pnts = real_points[new_objects[0][1], new_objects[0][2]]\n",
    "#                     yi = np.array([[pnts[0]], [pnts[2]]])\n",
    "                    #nned to project first\n",
    "\n",
    "                    yi,tmp1,tmp2 = slam.project(x[r], yi)\n",
    "\n",
    "\n",
    "                    idx = l[:,lid]\n",
    "                    x[int(idx[0])], x[int(idx[1])], L_r, L_y = slam.backProject(x[r], yi)\n",
    "\n",
    "                    P[s,:] = L_r @ P[r,:]\n",
    "                    P[:,s] = np.array(P[s,:]).conj().T\n",
    "                    P[s[:, np.newaxis],s] = L_r @ P[r[:, np.newaxis],r] @ L_r.conj().T + L_y @ M @ L_y.conj().T\n",
    "\n",
    "                    del new_objects[0]\n",
    "\n",
    "            \n",
    " \n",
    "    \n",
    "#     plt.cla()\n",
    "    \n",
    "#     idx = np.nonzero(l[0,:])\n",
    "#     lx = l[0,idx]\n",
    "#     ly = l[1,idx]\n",
    "    \n",
    "#     if len(lx[0]) > 0:\n",
    "#         plt.scatter(x[0], x[1], marker='s')\n",
    "#         plt.scatter(x[np.array(lx[0]).astype(int)], x[np.array(ly[0]).astype(int)])\n",
    "#         display.clear_output(wait=True)\n",
    "#         display.display(plt.gcf())\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #update robot position\n",
    "    ss = truth[img_id].strip().split()\n",
    "    true_x = float(ss[3])\n",
    "    true_y = float(ss[7])\n",
    "    true_z = float(ss[11])\n",
    "    true_x, true_y = int(true_x)+290, int(true_z)+90\n",
    "    \n",
    "    draw_x, draw_y = int(x[1])+290, int(x[0])+90\n",
    "    #drawlmk_x, drawlmk_y = int(x[3])+290, int(x[4])+90\n",
    "    for lid in old_objects:\n",
    "        drawlmk_x, drawlmk_y = int(x[int(l[:, lid][0])])+290, int(x[int(l[:, lid][1])])+90\n",
    "        cv2.circle(traj, (drawlmk_x, drawlmk_y), 1, (0,0,255), 3)\n",
    "#         print('created x = ', drawlmk_x, ' created y = drawlmk_y', drawlmk_y)\n",
    "#         print('original = ', old_objects)\n",
    "    \n",
    "    cv2.circle(traj, (draw_x, draw_y), 1, (img_id*255/4540,255-img_id*255/4540,0), 1)\n",
    "    #cv2.circle(traj, (drawlmk_x, drawlmk_y), 1, (img_id*255/4540,255-img_id*255/4540,0), 3)\n",
    "    cv2.circle(traj, (true_x,true_y), 1, (255,0,0), 2)\n",
    "    cv2.rectangle(traj, (10, 20), (600, 60), (0,0,0), -1)\n",
    "    #     text = \"Coordinates: x=%2fm y=%2fm z=%2fm\"%(x,y,z)\n",
    "    #     cv2.putText(traj, text, (20,40), cv2.FONT_HERSHEY_PLAIN, 1, (255,255,255), 1, 8)\n",
    "\n",
    "#     cv2.imshow('Road facing camera', img)\n",
    "    cv2.imshow('Trajectory', traj)\n",
    "    \n",
    "    cv2.imshow(\"Disp\", disparity)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the 'q' key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    # update the FPS counter\n",
    "#     fps.update()\n",
    "    \n",
    "\n",
    "    new_centroid = []\n",
    "#     print(true_x)\n",
    "#     print(true_y)\n",
    "    \n",
    "#     print(draw_x)\n",
    "#     print(draw_y)\n",
    "    #print('xy centroids without robot position = ', x)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# stop the timer and display FPS information\n",
    "vsLeft.release()\n",
    "vsRight.release()\n",
    "    # fps.stop()\n",
    "#print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
