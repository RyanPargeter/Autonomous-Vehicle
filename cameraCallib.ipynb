{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "lftObjpoints = [] # 3d point in real world space\n",
    "lftImgpoints = [] # 2d points in image plane.\n",
    "# Arrays to store object points and image points from all the images.\n",
    "rhtObjpoints = [] # 3d point in real world space\n",
    "rhtImgpoints = [] # 2d points in image plane.# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "lftObjpoints = [] # 3d point in real world space\n",
    "lftImgpoints = [] # 2d points in image plane.\n",
    "# Arrays to store object points and image points from all the images.\n",
    "rhtObjpoints = [] # 3d point in real world space\n",
    "rhtImgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# TODO: Use more stable identifiers\n",
    "left = cv2.VideoCapture(1)\n",
    "right = cv2.VideoCapture(2)\n",
    "\n",
    "# dramatically lower resolution to avoid overloading usb\n",
    "left.set(cv2.CAP_PROP_FRAME_WIDTH, 16)\n",
    "left.set(cv2.CAP_PROP_FRAME_HEIGHT, 16)\n",
    "right.set(cv2.CAP_PROP_FRAME_WIDTH, 16)\n",
    "right.set(cv2.CAP_PROP_FRAME_HEIGHT, 16)\n",
    "\n",
    "# Use MJPEG to avoid overloading the USB 2.0 bus at this resolution\n",
    "left.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "right.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "# Grab both frames first, then retrieve to minimize latency between cameras\n",
    "while True:\n",
    "    \n",
    "    if left.grab() and right.grab():\n",
    "    \n",
    "        _, leftFrame = left.retrieve()\n",
    "        leftWidth, leftHeight = leftFrame.shape[:2]\n",
    "        _, rightFrame = right.retrieve()\n",
    "        rightWidth, rightHeight = rightFrame.shape[:2]\n",
    "\n",
    "        # TODO: Calibrate the cameras and correct the images\n",
    "\n",
    "\n",
    "\n",
    "        lftGray = cv2.cvtColor(leftFrame,cv2.COLOR_BGR2GRAY)\n",
    "        rhtGray = cv2.cvtColor(rightFrame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        lftRet, lftCorners = cv2.findChessboardCorners(lftGray, (7,6),None)\n",
    "        rhtRet, rhtCorners = cv2.findChessboardCorners(rhtGray, (7,6),None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if lftRet == True:\n",
    "            lftObjpoints.append(objp)\n",
    "\n",
    "            lftCorners2 = cv2.cornerSubPix(lftGray,lftCorners,(11,11),(-1,-1),criteria)\n",
    "            lftImgpoints.append(lftCorners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            leftFrame = cv2.drawChessboardCorners(leftFrame, (7,6), lftCorners2,lftRet)\n",
    "               # show the output frame\n",
    "\n",
    "\n",
    "                   # If found, add object points, image points (after refining them)\n",
    "        if rhtRet == True:\n",
    "            rhtObjpoints.append(objp)\n",
    "\n",
    "            rhtCorners2 = cv2.cornerSubPix(lftGray,lftCorners,(11,11),(-1,-1),criteria)\n",
    "            rhtImgpoints.append(rhtCorners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            rightFrame = cv2.drawChessboardCorners(rightFrame, (7,6), rhtCorners2,rhtRet)\n",
    "               # show the output frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('left', leftFrame)\n",
    "    cv2.imshow('right', rightFrame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "left.release()\n",
    "right.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "vc = cv2.VideoCapture(1)\n",
    "vc.set(cv2.CAP_PROP_FRAME_WIDTH, 16)\n",
    "vc.set(cv2.CAP_PROP_FRAME_HEIGHT, 16)\n",
    "\n",
    "vc.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, img = vc.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6),None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        img = cv2.drawChessboardCorners(img, (7,6), corners2,ret)\n",
    "\n",
    "    cv2.imshow('right', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "\n",
    "#Save parameters into numpy file\n",
    "np.save(\"./lft_camera_params/imgpoints\", imgpoints)\n",
    "np.save(\"./lft_camera_params/ret\", ret)\n",
    "np.save(\"./lft_camera_params/K\", mtx)\n",
    "np.save(\"./lft_camera_params/dist\", dist)\n",
    "np.save(\"./lft_camera_params/rvecs\", rvecs)\n",
    "np.save(\"./lft_camera_params/tvecs\", tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3336: error: (-2:Unspecified error) in function 'void __cdecl cv::collectCalibrationData(const class cv::_InputArray &,const class cv::_InputArray &,const class cv::_InputArray &,int,class cv::Mat &,class cv::Mat &,class cv::Mat *,class cv::Mat &)'\n>  (expected: 'nimages == (int)imagePoints2.total()'), where\n>     'nimages' is 36\n> must be equal to\n>     '(int)imagePoints2.total()' is 28\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a9f6a5d3d745>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                                                                                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./right_camera_params/K.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./right_camera_params/dist.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                                                                                     \u001b[0mgray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                                                                                                    criteria = stereocalibration_criteria, flags = stereocalibration_flags)\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3336: error: (-2:Unspecified error) in function 'void __cdecl cv::collectCalibrationData(const class cv::_InputArray &,const class cv::_InputArray &,const class cv::_InputArray &,int,class cv::Mat &,class cv::Mat &,class cv::Mat *,class cv::Mat &)'\n>  (expected: 'nimages == (int)imagePoints2.total()'), where\n>     'nimages' is 36\n> must be equal to\n>     '(int)imagePoints2.total()' is 28\n"
     ]
    }
   ],
   "source": [
    "stereocalibration_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "stereocalibration_flags = cv2.CALIB_FIX_INTRINSIC\n",
    "## need to record a video from stero cameras at the same time and use that for callibration.\n",
    "stereocalibration_retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F = cv2.stereoCalibrate(objpoints, np.load(\"./lft_camera_params/imgpoints.npy\"), np.load(\"./right_camera_params/imgpoints.npy\"), \n",
    "                                                                                                                    np.load(\"./lft_camera_params/K.npy\"), np.load(\"./lft_camera_params/dist.npy\"), \n",
    "                                                                                                                    np.load(\"./right_camera_params/K.npy\"), np.load(\"./right_camera_params/dist.npy\"), \n",
    "                                                                                                                    gray.shape[::-1], \n",
    "                                                                                                                   criteria = stereocalibration_criteria, flags = stereocalibration_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VideoStream(src=1).start()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    img = vs.read()\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "        \n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    \n",
    "    # undistort\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import time\n",
    "import imutils\n",
    "from scipy.spatial import distance\n",
    "from typing import NamedTuple\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VideoStream(src=1).start()\n",
    "\n",
    "while True:\n",
    "   \n",
    "    frame = vs.read()\n",
    "    \n",
    "    \n",
    "       # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    # update the FPS counter\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
